---
title: "Partie 2"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

L’objectif est ici d'etudier un cas préesentant un problème de prédiction que ce soit dans le cadre de
la régression ou de la catégorisation. Vous devrez pour cela implémenter le code permettant de mettre
en oeuvre les points suivants :

— La lecture des données (que vous fournirez avec votre dossier en format .csv ou .xls ou .RData).
— Le pré-traitement des données si nécessaire.

— La validation croisée permettant d’évaluer les performances des méthodes suivantes :
— Modèle linéaire pénalisé par une fonction de régularisation elasticnet.
— Réseau de neuronnes avec une couche cachée.
— SVM.

— Autre m´ethode de votre choix sortant des techniques vues en cours (optionel).
Pour chaque type de méthode, vous testerez plusieurs ensembles de paramètres.


— Des graphiques permettant de comparer les résultats de chaque méthode avec les différents paramètres utilisés.
— Des graphiques permettant de comparer les meilleurs modèles des trois types de méthodes.

## Lecture des données

Notre jeu de données porte sur les haricots secs. 

Il comporte 13 611 observations (grains) pour 7 espèces différentes sur lesquelles nous souhaitons faire de la classification.

Les données ont été obtenues après des étapes de segmentation et d'extraction de caractéristiques sur des images prises par un système de vision par ordinateur utilisant une caméra haute résolution.

Les variables explicatives sont au nombre de 16 et sont relatives aux caractéristiques des grains : 

1.) Area (A): La surface d'une zone de haricot et le nombre de pixels à l'intérieur de ses limites.

2.) Perimeter (P): La circonférence d'un haricot est définie comme la longueur de sa bordure.

3.) Major axis length (L): La distance entre les extrémités de la ligne la plus longue qui peut être tracée à partir d'un haricot.

4.) Minor axis length (l): La plus longue ligne que l'on peut tracer à partir d'un haricot en étant perpendiculaire à l'axe principal.

5.) Aspect ratio (K): Définit la relation entre L et l.

6.) Eccentricity (Ec): Excentricité de l'ellipse ayant les mêmes moments que la région.

7.) Convex area (C): Nombre de pixels dans le plus petit polygone convexe qui peut contenir la surface d'une graine de haricot.

8.) Equivalent diameter (Ed): Le diamètre d'un cercle ayant la même surface que celle d'une graine de haricot.

9.) Extent (Ex): Le rapport entre les pixels de la boîte englobante et la surface du haricot.

10.) Solidity (S): Le rapport entre les pixels de la coquille convexe et ceux que l'on trouve dans les haricots.

11.) Roundness (R): Calculée à l'aide de la formule suivante : (4piA)/(P^2)

12.)Compactness (CO): Mesure la rondeur d'un objet : Ed/L

13.)ShapeFactor1 (SF1) = L/A

14.)ShapeFactor2 (SF2) = l/A

15.)ShapeFactor3 (SF3)

16.)ShapeFactor4 (SF4)

17.) Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)


```{r}
library(xlsx)
library(ggplot2)
library(lessR)
library(Hmisc)
library(dplyr)
```

```{r}
data = read.xlsx('Dry_Bean_Dataset.xlsx',sheetIndex = 1,stringsAsFactors=TRUE)
```


```{r}
head(data)
```


```{r}
dim(data)
```
## EDA

```{r}
summary(data)
```


```{r}
# test si présence de valeurs manquantes
sum(!complete.cases(data))
```


```{r}
ggplot(data = data, aes(x = Class)) +
    geom_bar()
```

```{r}
X = data[,c(1:16)]
y = data[,17]
```


```{r}
PieChart(Class, hole = 0, values = "%", data = data, main = "")
```
```{r}
hist.data.frame(X[,c(1:4)])
```


```{r}
hist.data.frame(X[,c(5:8)])
```


```{r}
hist.data.frame(X[,c(9:12)])
```


```{r}
hist.data.frame(X[,c(13:16)])
```


```{r}
library(GGally)
 
ggpairs(data, columns = 1:3, ggplot2::aes(colour=Class)) 
```


```{r}
ggpairs(data, columns = 4:7, ggplot2::aes(colour=Class))
```

## Séparation Train / Test

```{r}
library(caret)
library(glmnet)
```


```{r}
trainIndex <- createDataPartition(data$Class,p=0.7,list=F)

Train<- data[trainIndex,]
Test <- data[-trainIndex,]

preprocessParams <- preProcess(Train[,c(1:16)], method=c("center","scale"))


XTrain <- Train[,c(1:16)]
yTrain <- Train[,"Class"] 

XTest <- Test[,c(1:16)]
yTest <- Test[,"Class"] 

XTrain_scaled <- predict(preprocessParams,Train[,c(1:16)])

XTest_scaled <- predict(preprocessParams,Test[,c(1:16)])
```


```{r}
print(nrow(Train_set))
print(nrow(Test_set))
```


```{r}
# Distribution des classes dans les données de Train 
print(table(yTrain))
```

```{r}
# Distribution des classes dans les données de test 
print(table(yTest))
```

## Modèle linéaire pénalisé par une fonction de régularisation elasticnet.

```{r}
# alpha à définir avec gridsearch
model <- cv.glmnet(as.matrix(XTrain_scaled), yTrain, alpha = 0.3,family = "multinomial")
```

```{r}
summary(model)
```

```{r}
plot(model)
```
```{r}
model$lambda.min
```


```{r}
model$lambda.1se
```

```{r}
coef(model,s = "lambda.min")
```

```{r}
coef(model,s = "lambda.1se")
```


```{r}
# Make predictions
predicted.class <- model %>% predict(as.matrix(XTest_scaled),type="class")
```

```{r}
#predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
# Model accuracy
mean(predicted.class == Test$Class)
```
### Matrice de confusion

```{r}
confusionMatrix(as.factor(predicted.class), Test$Class, positive = NULL, dnn = c("Prediction", "Reference"))
```

## Réseau de neuronnes avec une couche cachée.


## SVM.

```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```

