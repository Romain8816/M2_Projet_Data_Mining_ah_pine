---
title: "TD4 - Détection de nouveauté par One-class SVM et Kernel PCA"
author: "Romain Dudoit, Franck Doronzo, Marie Vachet"
date: "12/14/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 Présentation de l'étude de cas

Le cas à l'étude provient du domaine de la médecine et correspond à des données sur le cancer du sein. 
Ces observations ont été recueillies à l’hôpital de l’université de Wisconsin par le Dr. Wolberg. Il
s’agit de prévoir si une tumeur est maligne ou bégnine à partir de différentes variables numériques. Le
jeu de données est non équilibré avec une majorité de cas bénins (∼2/3). Cela nous donne l’occasion
d’aborder la problématique sous l’angle de la détection de nouveauté qui est une tâche d’apprentissage
particulière. L’objectif du TP est alors de mettre en oeuvre une méthode supervisée, le one-class SVM
et une méthode non supervisée, le kernel PCA. Cette étude est tirée de l’article suivant : Hoffmann,
H. (2007). Kernel PCA for novelty detection. Pattern Recognition, 40(3), 863-874 dont la version
préliminaire est accessible à http://www.heikohoffmann.de/documents/hoffmann_kpca_preprint.pdf.



# 2 Lecture et description des données

```{r}
setwd(readClipboard())
print(readClipboard())
```

```{r}
D = read.table("breast-cancer-wisconsin.data",sep = ",", na.strings = "?")
```


```{r}
print(class(D))
print(str(D))
```


```{r}
print(head(D))
```


```{r}
summary(D)
```

# 3 Séparation des donneés en "train" et "test"

Nous allons pré-traiter les données et séparer celles-ci en deux sous-ensembles disjoints. L’un sera utilisé pour l’apprentissage, l’autre pour le test.


## 4. La variable D comporte des données manquantes. Identifiez les observations comportant au moins une donnée manquante à l’aide de la commande complete.cases. Vous devez identifier 16 cas.

```{r}
missval<-which(complete.cases(D)== F)
# Retourne la liste des numéros d'observation comportant des valeurs manquantes 

print(missval)
print(length(missval))
```

## 5. Modifiez D de sorte à ce qu'il ne possède que des données complètes

```{r}
D<-D[which(complete.cases(D)),]
```

## 6. Stockez dans la variable X les variables explicatives qui concernent les colonnes 2 à 10 (inclus) de D. 
La variable cible sera stockée dans la variable y qui est donnée par la colonne 11 de D.

```{r}
X<-D[,c(2:10)]
y<-D[,11]
```

## 7. Recodez y de sorte à ce que les valeurs 2 deviennent des 0 (bégnine) et les valeurs 4 deviennent des 1 (maligne).

```{r}
y<-factor(y)
levels(y) <- c(0,1)
```


## 8. Stockez dans la variable benin (resp. malin) les indices des observations correspondant à des
tumeurs bégnines (resp. maligne). Vous pourrez utiliser pour cela la commande which.

```{r}
benin<-which(y==0)
malin<-which(y==1)
```

## 9. Nous garderons dans l’ensemble d’entraınement uniquement les 200 premières observations bégnines. 
Stockez dans la variable train_set ces 200 observations. Dans l’ensemble de test vous garderez les observations bégnines qui ne sont pas dans l’ensemble d’entrainement et toutes les observations malignes. Vous stockerez les indices des observations de test dans la variable test set.

```{r}
train_set <- head(benin,200)
Xtrain <- as.matrix(X[train_set,])
ytrain<- as.matrix(y[train_set])

test_set <- c(benin[201:444],malin)
Xtest <- as.matrix(X[test_set,])
ytest <-as.matrix(y[test_set])
```


# 4 One-class SVM

## 10. Chargez la librairie e1071.

```{r}
library(e1071)
```

## 11 Stockez dans la variable oc_svm_fit les résultats de l’estimation du modèle à partir de l’ensemble d’entraînement. 
Vous utiliserez pour cela la commande svm. Vous utiliserez un noyau gaussien de paramètre gamma = 1/2, vous indiquerez que le type de modèle est one-classification.

```{r}
oc_svm_fit <- svm(as.matrix(X[train_set,]),y=NULL,kernel = "radial", type ="one-classification" , gamma = 1/2)
oc_svm_fit
```
## 12 A l’aide du modèle estimé stocké dans oc svm fit, vous prédirez les scores des observations de test. 
Pour cela, utilisez la commande predict et vous indiquerez de façcon adéquate le paramètre decision.values.

```{r}
oc_svm_pred_test  <- predict(oc_svm_fit, X[test_set,],decision.values = TRUE)
```

## 13. Entrez, exécutez et commentez les commandes suivantes : 

```{r}
attr (oc_svm_pred_test ,"decision.values")
oc_svm_score_test = -as.numeric(attr(oc_svm_pred_test,"decision.values"))
```
# 5 Courbe ROC

## 14. Charger la librairie ROCR
## 15.Entrez, exécutez et commentez les commandes suivantes :

```{r}
library(ROCR)
pred_oc_svm=prediction(oc_svm_score_test,y[test_set])
oc_svm_roc = performance(pred_oc_svm, measure = "tpr", x.measure = "fpr")
plot(oc_svm_roc)
```
## 16. Commentez les performances du modèle.

Commentaires


# 6 Kernel PCA

## 17. Entrez, exécutez et commentez les commandes suivantes :

```{r}
library(kernlab)
kernel=rbfdot(sigma=1/8)
Ktrain=kernelMatrix(kernel,as.matrix(X[train_set,]))
```

```{r}
kernel
```

```{r}
Ktrain
```

Commentaires

## 18. Entrez, exécutez et commentez les commandes suivantes :

```{r}
k2=apply(Ktrain,1,sum) # lignes
k3=apply(Ktrain,2,sum) # colonnes 
k4=sum(Ktrain)
n=nrow(Ktrain)
KtrainCent=matrix(0,ncol=n,nrow=n)
for (i in 1:n)
  {
    for (j in 1:n)
      {
        KtrainCent[i,j]=Ktrain[i,j]-1/n*k2[i]-1/n*k3[j]+1/n^2*k4
      }
}
```

En particulier faites le rapprochement entre les variables k2, k3 et k4 et l’équation (1)


Commentaires


## 19. Procéder à la décomposition spectrale de la matrice KtrainCent en utilisant la commande eigen. Vous stockerez le résultat dans la variable eigen_KtrainCent.

```{r}
eigen_KtrainCent = eigen(KtrainCent)
eigen_KtrainCent
```


## 20. On choisit de garder s = 80 axes principaux. Ainsi instanciez une variable s=80. Les coeﬃcients αm, ∀m = 1, . . . , 80 sont obtenus par la ligne de code suivante :

```{r}
s = 80
A=eigen_KtrainCent$vectors[,1:s]%*%diag(1/sqrt(
  eigen_KtrainCent$values[1:s]))
A
```

## 21. Entrez, exécutez et commentez la commande suivante :

```{r}
K=kernelMatrix(kernel,X)
```

## 22. A partir de la variable K et en vous inspirant des questions (et indications) précédentes, instanciez dans les variables p1, p2 et p3 les 3 termes composants l’équation donnée en (4).

```{r}
# calculer le premier  n  terme de la formule (4)
p1=as.numeric(diag(K))
# calculer le deuxieme terme de la formule (4)
p2=as.numeric(-2/n*apply(as.matrix(K[,train_set]),1,sum))
# calculer le troisieme terme de la formule (4)
p3=as.numeric(1/(n^2)*sum(K[train_set,train_set]))
```

## 23. A partir des résultats précédents, stockez dans une variable ps le vecteur qui pour toute observation des données de test donne la quantité (4).

```{r}
ps=p1[test_set]+p2[test_set]+p3
```


## 24. A partir de la variable K et en vous inspirant des questions précédentes, instanciez dans les variables f1, f2, f3 et f4 les termes successifs de (5). Vous remarquerez que certains termes ont déjà été calculés précédemment.

```{r}
f1=K[,train_set]%*% A
f2=as.numeric(-1/n*(t(A)%*%apply(K[train_set,train_set],1,sum)))
f3=as.matrix(-1/n*apply(K[,train_set],1,sum))%*% t(as.matrix(apply(A,2,sum)))
f4=1/(n^2)*sum(K[train_set,train_set])*apply(A,2,sum)
```


## 25. A partir des résultats précédents, stockez dans une variable fl le vecteur qui pour toute observation des données de test donne la quantité (5) (Remarque : fl représente une matrice dont le
nombre de lignes vaut le nombre de données tests et le nombre de colonne, le nombre d’axes principaux retenus).

```{r}
f2bis=matrix(rep(f2,683), nrow=683,ncol=80,byrow=T)

f4bis=matrix(rep(f4,683), nrow=683,ncol=80,byrow=T)

fl=f1[test_set,]+f2bis[test_set,]+f3[test_set,]+f4bis[test_set,]
```


## 26. A partir des résultats précédents, stockez dans une variable kpca score test le vecteur qui pour toute observation des donneés de test donne le score défini en (3).

```{r}

```


## 27. Ecrivez le code qui à partir de la variable kpca score test permet d’obtenir la courbe ROC. Pour comparer la courbe avec celle du one-class SVM vous pourrez ajouter dans la commande
plot le paramètre add=TRUE. Commentez le graphique obtenu.

```{r}

```

Commentaires
